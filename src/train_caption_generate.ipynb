{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf7685ca72d845c89df265d574c3013f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import string\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import re\n",
    "from pickle import dump, load\n",
    "# from tf.keras.applications.xception import Xception, preprocess_input\n",
    "# from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# from tf.keras.utils import to_categorical\n",
    "# from tf.keras.utils import to_categorical\n",
    "# from tf.keras.layers import add, Input, Dense, LSTM, Embedding, Dropout\n",
    "# from tf.keras.models import Model, load_model\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm().pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load, process/clean, and save image text dataset (id + captions)\n",
    "\n",
    "def load_file(filepath: str) -> str:\n",
    "    \"\"\"\n",
    "    @param filepath path of the file to be loaded\n",
    "    @return the contents of the file\n",
    "    \"\"\"\n",
    "    file = open(filepath, \"r\")\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text\n",
    "\n",
    "def get_descriptions(dataset_text_filepath: str) -> dict[str, list[str]]:\n",
    "    \"\"\"\n",
    "    @param dataset_text_filepath path of the file containing image ids and captions\n",
    "        >>> file contents\n",
    "        1000268201_693b08cb0e.jpg#0\\tA child in a pink dress is climbing up a set of stairs in an entry way .\\n\n",
    "        1000268201_693b08cb0e.jpg#1\\tA girl going into a wooden building .\\n\n",
    "        ...\n",
    "    @return a dictionary (key: image id -> value: array of image captions)\n",
    "    \"\"\"\n",
    "    text = load_file(dataset_text_filepath)\n",
    "    entries = text.split(\"\\n\")\n",
    "\n",
    "    descriptions = {}\n",
    "    for entry in entries:\n",
    "        if entry == \"\":\n",
    "            continue\n",
    "        img_id, caption = entry.split(\"\\t\")\n",
    "        img_id = img_id[:-2] # Strip numbers off id (ie 1000268201_693b08cb0e.jpg#0 -> 1000268201_693b08cb0e.jpg)\n",
    "        if img_id not in descriptions:\n",
    "            descriptions[img_id] = [caption]\n",
    "        else:\n",
    "            descriptions[img_id].append(caption)\n",
    "\n",
    "    return descriptions\n",
    "\n",
    "def clean_descriptions(descriptions: dict[str, list[str]]) -> None:\n",
    "    \"\"\"\n",
    "    Clean the entries in the descriptions dictionary in-place.\n",
    "    Convert all letters to lowercase, removes punctuation, removes hanging \"s\" and \"a\"s,\n",
    "    removes words containing numbers, and removes duplicate whitespace\n",
    "\n",
    "    @param descriptions a dictionary (key: image id -> value: array of image captions)\n",
    "    \"\"\"\n",
    "    for img_id, captions in descriptions.items():\n",
    "        for i, caption in enumerate(captions):\n",
    "            # Convert to lowercase\n",
    "            caption = caption.lower()\n",
    "\n",
    "            # Remove punctuation\n",
    "            caption = caption.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "\n",
    "            # Remove hanging \"s\" and \"a\"s\n",
    "            caption = caption.replace(\" s \", \" \")\n",
    "            caption = caption.replace(\" a \", \" \")\n",
    "\n",
    "            # Remove words with letters\n",
    "            caption = re.sub(r\"\\w*\\d\\w*\", \"\", caption)\n",
    "\n",
    "            # Remove duplicate whitespace\n",
    "            caption = \" \".join(caption.split())\n",
    "\n",
    "            descriptions[img_id][i] = caption\n",
    "\n",
    "def get_vocab(descriptions: dict[str, list[str]]) -> set[str]:\n",
    "    \"\"\"\n",
    "    @param descriptions a dictionary (key: image id -> value: array of image captions)\n",
    "    @return set of all words used in captions\n",
    "    \"\"\"\n",
    "    vocab = set()\n",
    "    for img_id, captions in descriptions.items():\n",
    "        [vocab.update(words.split()) for words in captions]\n",
    "    return vocab\n",
    "\n",
    "def save_descriptions(filename: str, descriptions: dict[str, list[str]]) -> None:\n",
    "    \"\"\"\n",
    "    Write the descriptions back to a file\n",
    "\n",
    "    @param filename the name of the file to write the descriptions to\n",
    "    @param descriptions a dictionary (key: image id -> value: array of image captions)\n",
    "    \"\"\"\n",
    "    lines = list()\n",
    "    for img_id, captions in descriptions.items():\n",
    "        for caption in captions:\n",
    "            description = img_id + \"\\t\" + caption\n",
    "            lines.append(description)\n",
    "\n",
    "    data = \"\\n\".join(lines)\n",
    "    file = open(filename, \"w\")\n",
    "    file.write(data)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process image dataset\n",
    "\n",
    "def extract_features(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_text_dirname = \"Flicker8k_text\"\n",
    "dataset_image_dirname = \"Flicker8k_dataset\"\n",
    "text_filename = \"Flickr8k.token.txt\"\n",
    "\n",
    "text_path = dataset_text_dirname + \"/\" + text_filename\n",
    "descriptions = get_descriptions(text_path)\n",
    "clean_descriptions(descriptions)\n",
    "\n",
    "vocab = get_vocab(descriptions)\n",
    "\n",
    "save_descriptions(\"descriptions.txt\", descriptions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.3 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0a6fbbda9a332fbeb69584f890bbc13262a5a64e4479e957e165bbafac6deac3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
